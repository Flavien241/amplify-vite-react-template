import type { APIGatewayProxyHandler } from "aws-lambda";

export const handler: APIGatewayProxyHandler = async (event) => {
  // CORS gÃ©rÃ© par Function URL, pas besoin de headers manuels

  try {
    if (!event.body) {
      return {
        statusCode: 400,
        body: JSON.stringify({ error: "Corps de requÃªte manquant" }),
      };
    }

    const { todoContent } = JSON.parse(event.body);

    if (!todoContent) {
      return {
        statusCode: 400,
        body: JSON.stringify({ error: "todoContent est requis" }),
      };
    }

    const openaiApiKey = process.env.OPENAI_API_KEY;
    console.log(
      "ðŸ”‘ ClÃ© API OpenAI prÃ©sente:",
      !!openaiApiKey,
      "Longueur:",
      openaiApiKey?.length
    );

    if (!openaiApiKey) {
      return {
        statusCode: 500,
        body: JSON.stringify({ error: "ClÃ© API OpenAI non configurÃ©e" }),
      };
    }

    const requestPayload = {
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content:
            "Tu es un assistant qui aide Ã  dÃ©composer les tÃ¢ches en sous-tÃ¢ches plus petites et rÃ©alisables. RÃ©ponds avec une liste de 3-5 sous-tÃ¢ches concrÃ¨tes en franÃ§ais, une par ligne, sans numÃ©rotation.",
        },
        {
          role: "user",
          content: `DÃ©compose cette tÃ¢che en sous-tÃ¢ches : "${todoContent}"`,
        },
      ],
      max_tokens: 300,
      temperature: 0.7,
    };

    console.log(
      "ðŸ“¤ RequÃªte vers OpenAI:",
      JSON.stringify(requestPayload, null, 2)
    );

    // Appel Ã  l'API OpenAI
    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${openaiApiKey}`,
      },
      body: JSON.stringify(requestPayload),
    });

    if (!response.ok) {
      const errorData = await response.text();
      console.error("âŒ Erreur OpenAI dÃ©taillÃ©e:", {
        status: response.status,
        statusText: response.statusText,
        headers: Object.fromEntries(response.headers.entries()),
        body: errorData,
      });
      return {
        statusCode: 500,
        body: JSON.stringify({
          error: "Erreur lors de l'appel Ã  OpenAI",
          details: `HTTP ${response.status}: ${errorData}`,
          openaiStatus: response.status,
        }),
      };
    }

    const data = await response.json();
    const subtasks =
      data.choices[0]?.message?.content
        ?.split("\n")
        .filter((task: string) => task.trim())
        .map((task: string) => task.replace(/^[-*â€¢]\s*/, "").trim()) || [];

    return {
      statusCode: 200,
      body: JSON.stringify({ subtasks }),
    };
  } catch (error) {
    console.error("Erreur dans la fonction lambda:", error);
    return {
      statusCode: 500,
      body: JSON.stringify({ error: "Erreur interne du serveur" }),
    };
  }
};
